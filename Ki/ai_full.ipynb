{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"C:\\\\_Thesis\\\\Kennwerte\\\\1_0_1j.txt\")\n",
    "amountOfValidationRuns = 1000\n",
    "amountOfValidationDatasets = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "secure_data = np.loadtxt(\"C:\\\\_Thesis\\\\Kennwerte\\\\3_1_1.txt\")\n",
    "secure_data = secure_data[:amountOfValidationDatasets, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "C:\\_Thesis\\4. Kennwerte\\3_1_1.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\_Thesis\\KI\\ai.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/_Thesis/KI/ai.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m insecure_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mloadtxt(\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m_Thesis\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m4. Kennwerte\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m3_1_1.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_Thesis/KI/ai.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m insecure_data \u001b[39m=\u001b[39m insecure_data[:amountOfValidationDatasets, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mjens\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:1356\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1353\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[0;32m   1354\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1356\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39mdtype, comment\u001b[39m=\u001b[39mcomment, delimiter\u001b[39m=\u001b[39mdelimiter,\n\u001b[0;32m   1357\u001b[0m             converters\u001b[39m=\u001b[39mconverters, skiplines\u001b[39m=\u001b[39mskiprows, usecols\u001b[39m=\u001b[39musecols,\n\u001b[0;32m   1358\u001b[0m             unpack\u001b[39m=\u001b[39munpack, ndmin\u001b[39m=\u001b[39mndmin, encoding\u001b[39m=\u001b[39mencoding,\n\u001b[0;32m   1359\u001b[0m             max_rows\u001b[39m=\u001b[39mmax_rows, quote\u001b[39m=\u001b[39mquotechar)\n\u001b[0;32m   1361\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32mc:\\Users\\mjens\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:975\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m    973\u001b[0m     fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(fname)\n\u001b[0;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 975\u001b[0m     fh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlib\u001b[39m.\u001b[39m_datasource\u001b[39m.\u001b[39mopen(fname, \u001b[39m'\u001b[39m\u001b[39mrt\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39mencoding)\n\u001b[0;32m    976\u001b[0m     \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         encoding \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fh, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mjens\\anaconda3\\Lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[1;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39mopen(path, mode, encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n",
      "File \u001b[1;32mc:\\Users\\mjens\\anaconda3\\Lib\\site-packages\\numpy\\lib\\_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[1;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m    531\u001b[0m                               encoding\u001b[39m=\u001b[39mencoding, newline\u001b[39m=\u001b[39mnewline)\n\u001b[0;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: C:\\_Thesis\\4. Kennwerte\\3_1_1.txt not found."
     ]
    }
   ],
   "source": [
    "insecure_data = np.loadtxt(\"C:\\\\_Thesis\\\\Kennwerte\\\\3_1_1.txt\")\n",
    "insecure_data = insecure_data[:amountOfValidationDatasets, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insecure_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9646109756097561, 80, 1.0, 0, 0.0], [0.966745731707317, 80, 1.0, 0, 0.0], [0.9525445121951219, 80, 1.0, 0, 0.0], [0.9660957317073171, 80, 1.0, 0, 0.0], [0.9709493902439025, 80, 1.0, 0, 0.0], [0.9612591463414634, 80, 1.0, 0, 0.0], [0.9515432926829268, 80, 1.0, 0, 0.0], [0.964689024390244, 80, 1.0, 0, 0.0], [0.9611579268292683, 80, 1.0, 0, 0.0], [0.9647786585365854, 80, 1.0, 0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "ExtraTreesRegressor(bootstrap=False, criterion='friedman_mse', max_depth=None,\n",
    "                    max_features='auto', max_leaf_nodes=None,\n",
    "                    min_impurity_decrease=0.0, \n",
    "                    min_samples_leaf=1, min_samples_split=2,\n",
    "                    min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
    "                    n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
    "                    warm_start=False)\n",
    "                    \n",
    "etr = ExtraTreesRegressor()\n",
    "etrResults = []\n",
    "for i in range(amountOfValidationRuns):    \n",
    "    tempResult = []    \n",
    "    secureDetected = 0\n",
    "    insecureDetected = 0\n",
    "    x = data[:, :-1]  # Features\n",
    "    y = data[:, -1]  # Target variable\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    etr.fit(x_train, y_train)\n",
    "    y_pred = etr.predict(x_test)\n",
    "    tempResult.append(etr.score(x,y))\n",
    "    \n",
    "    for X in secure_data:\n",
    "        X = X.reshape(1,-1)\n",
    "        yhat = etr.predict(X)\n",
    "        if np.floor(yhat[0]) == 0:\n",
    "            secureDetected = secureDetected + 1\n",
    "    tempResult.append(secureDetected)\n",
    "    tempResult.append(secureDetected/amountOfValidationDatasets)\n",
    "\n",
    "    for X in insecure_data:\n",
    "        X = X.reshape(1,-1)\n",
    "        yhat = etr.predict(X)\n",
    "        if np.floor(yhat[0]) == 1:\n",
    "            insecureDetected = insecureDetected + 1\n",
    "    tempResult.append(insecureDetected)\n",
    "    tempResult.append(insecureDetected/amountOfValidationDatasets)\n",
    "\n",
    "    etrResults.append(tempResult)\n",
    "print(etrResults)\n",
    "np.savetxt('extraTreeRegressor.csv', etrResults,fmt='%f', delimiter=\",\", header=\"Score,SecurePositives,SecurePositivesPercentage,InsecurePositives,InsecurePositivesPercentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9908536585365854, 17, 0.2125, 0, 0.0], [0.9878048780487805, 17, 0.2125, 0, 0.0], [0.9847560975609756, 17, 0.2125, 0, 0.0], [0.9878048780487805, 0, 0.0, 0, 0.0], [0.9817073170731707, 16, 0.2, 0, 0.0], [0.9878048780487805, 21, 0.2625, 0, 0.0], [0.9847560975609756, 18, 0.225, 0, 0.0], [0.9832317073170732, 5, 0.0625, 0, 0.0], [0.9862804878048781, 22, 0.275, 0, 0.0], [0.9878048780487805, 9, 0.1125, 0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier()\n",
    "clfResults = []\n",
    "for i in range(amountOfValidationRuns):    \n",
    "    tempResult = []    \n",
    "    secureDetected = 0\n",
    "    insecureDetected = 0\n",
    "    x = data[:, :-1]  # Features\n",
    "    y = data[:, -1]  # Target variable\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    tempResult.append(clf.score(x,y))\n",
    "    \n",
    "    for X in secure_data:\n",
    "        X = X.reshape(1,-1)\n",
    "        yhat = clf.predict(X)\n",
    "        if np.floor(yhat[0]) == 0:\n",
    "            secureDetected = secureDetected + 1\n",
    "    tempResult.append(secureDetected)\n",
    "    tempResult.append(secureDetected/amountOfValidationDatasets)\n",
    "\n",
    "    for X in insecure_data:\n",
    "        X = X.reshape(1,-1)\n",
    "        yhat = clf.predict(X)\n",
    "        if np.floor(yhat[0]) == 1:\n",
    "            insecureDetected = insecureDetected + 1\n",
    "    tempResult.append(insecureDetected)\n",
    "    tempResult.append(insecureDetected/amountOfValidationDatasets)\n",
    "\n",
    "    clfResults.append(tempResult)\n",
    "print(clfResults)\n",
    "np.savetxt('extraTreeClassifier.csv', clfResults,fmt='%f', delimiter=\",\", header=\"Score,SecurePositives,SecurePositivesPercentage,InsecurePositives,InsecurePositivesPercentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.875, 30, 0.375, 0, 0.0], [0.8689024390243902, 28, 0.35, 0, 0.0], [0.875, 30, 0.375, 0, 0.0], [0.8734756097560976, 29, 0.3625, 0, 0.0], [0.875, 30, 0.375, 0, 0.0], [0.875, 30, 0.375, 0, 0.0], [0.8719512195121951, 30, 0.375, 0, 0.0], [0.875, 29, 0.3625, 0, 0.0], [0.8704268292682927, 30, 0.375, 0, 0.0], [0.8734756097560976, 29, 0.3625, 0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_leaf_nodes=3, random_state=0)\n",
    "dtResults = []\n",
    "for i in range(amountOfValidationRuns):    \n",
    "    tempResult = []    \n",
    "    secureDetected = 0\n",
    "    insecureDetected = 0\n",
    "    x = data[:, :-1]  # Features\n",
    "    y = data[:, -1]  # Target variable\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    dt.fit(x_train, y_train)\n",
    "    y_pred = dt.predict(x_test)\n",
    "    tempResult.append(dt.score(x,y))\n",
    "    \n",
    "    for X in secure_data:\n",
    "        X = X.reshape(1,-1)\n",
    "        yhat = dt.predict(X)\n",
    "        if np.floor(yhat[0]) == 0:\n",
    "            secureDetected = secureDetected + 1\n",
    "    tempResult.append(secureDetected)\n",
    "    tempResult.append(secureDetected/amountOfValidationDatasets)\n",
    "\n",
    "    for X in insecure_data:\n",
    "        X = X.reshape(1,-1)\n",
    "        yhat = dt.predict(X)\n",
    "        if np.floor(yhat[0]) == 1:\n",
    "            insecureDetected = insecureDetected + 1\n",
    "    tempResult.append(insecureDetected)\n",
    "    tempResult.append(insecureDetected/amountOfValidationDatasets)\n",
    "\n",
    "    dtResults.append(tempResult)\n",
    "print(dtResults)\n",
    "np.savetxt('decisionTree.csv', dtResults,fmt='%f', delimiter=\",\", header=\"Score,SecurePositives,SecurePositivesPercentage,InsecurePositives,InsecurePositivesPercentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9817073170731707, 21, 0.2625, 0, 0.0], [0.9847560975609756, 64, 0.8, 0, 0.0], [0.9832317073170732, 24, 0.3, 0, 0.0], [0.9801829268292683, 0, 0.0, 0, 0.0], [0.9862804878048781, 78, 0.975, 0, 0.0], [0.9847560975609756, 0, 0.0, 0, 0.0], [0.9878048780487805, 25, 0.3125, 0, 0.0], [0.9832317073170732, 36, 0.45, 0, 0.0], [0.9847560975609756, 0, 0.0, 0, 0.0], [0.9923780487804879, 56, 0.7, 0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate=0.1)\n",
    "clfResults = []\n",
    "for i in range(amountOfValidationRuns):    \n",
    "    tempResult = []    \n",
    "    secureDetected = 0\n",
    "    insecureDetected = 0\n",
    "    x = data[:, :-1]  # Features\n",
    "    y = data[:, -1]  # Target variable\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    tempResult.append(clf.score(x,y))\n",
    "    \n",
    "    for X in secure_data:\n",
    "        X = X.reshape(1,-1)\n",
    "        yhat = clf.predict(X)\n",
    "        if np.floor(yhat[0]) == 0:\n",
    "            secureDetected = secureDetected + 1\n",
    "    tempResult.append(secureDetected)\n",
    "    tempResult.append(secureDetected/amountOfValidationDatasets)\n",
    "\n",
    "    for X in insecure_data:\n",
    "        X = X.reshape(1,-1)\n",
    "        yhat = clf.predict(X)\n",
    "        if np.floor(yhat[0]) == 1:\n",
    "            insecureDetected = insecureDetected + 1\n",
    "    tempResult.append(insecureDetected)\n",
    "    tempResult.append(insecureDetected/amountOfValidationDatasets)\n",
    "\n",
    "    clfResults.append(tempResult)\n",
    "print(clfResults)\n",
    "np.savetxt('gradientBoosting.csv', clfResults,fmt='%f', delimiter=\",\", header=\"Score,SecurePositives,SecurePositivesPercentage,InsecurePositives,InsecurePositivesPercentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RidgeClassifier.__init__() got an unexpected keyword argument 'normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\_Thesis\\KI\\ai.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/_Thesis/KI/ai.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m RidgeClassifier(alpha\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, class_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, copy_X\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fit_intercept\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_Thesis/KI/ai.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                 max_iter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, solver\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_Thesis/KI/ai.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                 tol\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_Thesis/KI/ai.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m rc \u001b[39m=\u001b[39m RidgeClassifier()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/_Thesis/KI/ai.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m rcResults \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: RidgeClassifier.__init__() got an unexpected keyword argument 'normalize'"
     ]
    }
   ],
   "source": [
    "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
    "                max_iter=None, random_state=None, solver='auto',\n",
    "                tol=0.001)\n",
    "rc = RidgeClassifier()\n",
    "rcResults = []\n",
    "for i in range(amountOfValidationRuns):    \n",
    "    tempResult = []    \n",
    "    secureDetected = 0\n",
    "    insecureDetected = 0\n",
    "    x = data[:, :-1]  # Features\n",
    "    y = data[:, -1]  # Target variable\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    rc.fit(x_train, y_train)\n",
    "    y_pred = rc.predict(x_test)\n",
    "    tempResult.append(rc.score(x,y))\n",
    "    \n",
    "    for X in secure_data:\n",
    "        X = X.reshape(1,-1)\n",
    "        yhat = rc.predict(X)\n",
    "        if np.floor(yhat[0]) == 0:\n",
    "            secureDetected = secureDetected + 1\n",
    "    tempResult.append(secureDetected)\n",
    "    tempResult.append(secureDetected/amountOfValidationDatasets)\n",
    "\n",
    "    for X in insecure_data:\n",
    "        X = X.reshape(1,-1)\n",
    "        yhat = rc.predict(X)\n",
    "        if np.floor(yhat[0]) == 1:\n",
    "            insecureDetected = insecureDetected + 1\n",
    "    tempResult.append(insecureDetected)\n",
    "    tempResult.append(insecureDetected/amountOfValidationDatasets)\n",
    "\n",
    "    rcResults.append(tempResult)\n",
    "print(rcResults)\n",
    "np.savetxt('ridgeClassifier.csv', rcResults,fmt='%f', delimiter=\",\", header=\"Score,SecurePositives,SecurePositivesPercentage,InsecurePositives,InsecurePositivesPercentage\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
